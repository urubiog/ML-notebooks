{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f2e098",
   "metadata": {
    "papermill": {
     "duration": 0.00419,
     "end_time": "2025-02-05T17:09:25.229394",
     "exception": false,
     "start_time": "2025-02-05T17:09:25.225204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "The MLP (Multi-Layer Perceptron) neural network model for handwritten digit prediction using the MNIST dataset in this example has a simple architecture, described below, along with its functionality.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "The first input layer depends on the resolution of the images, which in this case are 28x28 (784 pixels). The second layer contains a total of 128 units, and finally, the last layer has 10 neurons corresponding to the possible digits in the decimal base (0-9).\n",
    "\n",
    "$$\n",
    "\\text{784 - 128 - 10}\n",
    "$$\n",
    "\n",
    "### Activation Functions\n",
    "\n",
    "For the interests of simplicity, we choose the ReLU (Rectified Linear Unit) activation function for the hidden layer and Sigmoid for the final layer. This is because the Sigmoid function transforms the network's output (which can have any real values) into a value between 0 and 1, allowing each output to be interpreted as the probability of the corresponding class in a binary classification task. However, unlike Softmax, Sigmoid does not ensure that the sum of all outputs equals 1. Instead, each output is treated independently.\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(z) = \\max{(0, z)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Sigmoid}(Z) = \\frac{e^{z_i}}{\\sum_{j=1}^K{e^{z_j}}}\n",
    "$$\n",
    "\n",
    "And, the derivatives for each function...\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\text{ReLU}(z) = \n",
    "\\begin{cases} \n",
    "1 & \\text{if } z > 0 \\\\\n",
    "0 & \\text{if } z \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}Z} \\text{Sigmoid}(Z) = \\text{Sigmoid}(Z) \\cdot (1 - \\text{Sigmoid}(Z))\n",
    "$$\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "The Categorical Cross-Entropy (CE) function is used in classification problems, particularly when the output of the model is a probability distribution over multiple classes, as in the case of the softmax activation. In this case, the CE measures how well the predicted probability distribution matches the true class labels (0-9).\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} y_{ij} \\log (\\hat{y}_{ij})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_{ij}$ is the true label (1 if class $j$ is correct, 0 otherwise).\n",
    "- $\\hat{y}_{ij}$ is the predicted probability for class $j$ for example $i$.\n",
    "- $N$ is the number of training examples.\n",
    "- $K$ is the number of classes (for MNIST, $K = 10$).\n",
    "\n",
    "The derivative of the Categorical Cross-Entropy (CE) with respect to the predictions pre-activations is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_{i}} = \\frac{\\hat{y}_{i} - y_{i}}{N}\n",
    "$$\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "For the optimizer, we will use MGD (Mini-batch Gradient Descent) with a batch size $m$ of 128. Using the Backpropagation algorithm, we will reduce the loss by updating the parameters according to the differentiation of the previous functions, as shown in the adjacent formulas.\n",
    "\n",
    "The parameters (weights and biases) are updated as shown below. We introduce a new variable $\\delta$, which will be used to optimize the process and make it more manageable in terms of computational resources.\n",
    "\n",
    "$$\n",
    "\\delta^{L}_i = \\frac{\\partial{\\mathcal{L}}}{\\partial{z^L_i}} = \\frac{\\partial{\\mathcal{L}}}{\\partial{\\hat{y}^L_i}} · \\frac{\\partial{\\hat{y}^L_i}}{\\partial{z^L_i}}\n",
    "$$\n",
    "\n",
    "For the last layer $L$.\n",
    "\n",
    "$$\n",
    "\\delta^{(l-1)}_i = \\frac{\\partial{\\mathcal{L}}}{\\partial{z^{(l-1)}_i}} = \\left(\\sum_{j}{\\delta^{(l)}_j · w^{(l)}_{ij}}\\right) · \\frac{\\partial{a^{(l-1)}_i}}{\\partial{z^{(l-1)}_i}}\n",
    "$$\n",
    "\n",
    "For the layer preceding to $l$.\n",
    "\n",
    "$$\n",
    "b^{(l)}_i := b^{(l)}_i - \\alpha \\frac{\\partial{\\mathcal{L}}}{\\partial{b^{(l)}_{i}}} = \\delta^{(l)}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "w^{(l)}_{ij} := w^{(l)}_{ij} - \\alpha \\frac{\\partial{\\mathcal{L}}}{\\partial{w^{(l)}_{ij}}} = \\delta^{(l)}_i · a^{(l-1)}_j\n",
    "$$\n",
    "\n",
    "For each iteration.\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\eta \\frac{1}{m} \\sum^{m}_{i=1}{\\nabla_{\\theta} \\mathcal{L}(\\theta;x^{(i)}, y^{(i)})}\n",
    "$$\n",
    "\n",
    "For each batch.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Regarding hyperparameters, we will use standardized values:\n",
    "\n",
    "$$\n",
    "\\eta: \\text{learning rate} = 0.01\n",
    "$$\n",
    "\n",
    "$$\n",
    "m: \\text{batch size} = 128\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ac057a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:09:25.238658Z",
     "iopub.status.busy": "2025-02-05T17:09:25.238271Z",
     "iopub.status.idle": "2025-02-05T17:09:26.394954Z",
     "shell.execute_reply": "2025-02-05T17:09:26.393517Z"
    },
    "papermill": {
     "duration": 1.163716,
     "end_time": "2025-02-05T17:09:26.397413",
     "exception": false,
     "start_time": "2025-02-05T17:09:25.233697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dacd09a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:09:26.405848Z",
     "iopub.status.busy": "2025-02-05T17:09:26.405205Z",
     "iopub.status.idle": "2025-02-05T17:09:34.694936Z",
     "shell.execute_reply": "2025-02-05T17:09:34.693453Z"
    },
    "papermill": {
     "duration": 8.295733,
     "end_time": "2025-02-05T17:09:34.696836",
     "exception": false,
     "start_time": "2025-02-05T17:09:26.401103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "train_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259541a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:09:34.706855Z",
     "iopub.status.busy": "2025-02-05T17:09:34.706435Z",
     "iopub.status.idle": "2025-02-05T17:09:34.932350Z",
     "shell.execute_reply": "2025-02-05T17:09:34.931027Z"
    },
    "papermill": {
     "duration": 0.232509,
     "end_time": "2025-02-05T17:09:34.934380",
     "exception": false,
     "start_time": "2025-02-05T17:09:34.701871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 40000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data division\n",
    "data = np.array(train_data) # 42_000 examples\n",
    "test_data = np.array(test_data)   # 28_000 examples (without labels)\n",
    "\n",
    "m, n = train_data.shape\n",
    "\n",
    "train_data = data[2000:m].T\n",
    "X_train = train_data[1: n]\n",
    "Y_train = train_data[0]\n",
    "\n",
    "eval_data = data[:2000].T\n",
    "X_eval = eval_data[1: n]\n",
    "Y_eval = eval_data[0]\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56464cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:09:34.943120Z",
     "iopub.status.busy": "2025-02-05T17:09:34.942719Z",
     "iopub.status.idle": "2025-02-05T17:09:35.134045Z",
     "shell.execute_reply": "2025-02-05T17:09:35.132611Z"
    },
    "papermill": {
     "duration": 0.197982,
     "end_time": "2025-02-05T17:09:35.136117",
     "exception": false,
     "start_time": "2025-02-05T17:09:34.938135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 784), (40000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "test_data = test_data.reshape(28000, 28, 28)\n",
    "\n",
    "X_train = X_train.astype(np.float64).T\n",
    "X_eval = X_eval.astype(np.float64).T\n",
    "\n",
    "max_val = X_train.max() # 255.0\n",
    "\n",
    "X_train /= max_val # Normalization\n",
    "X_eval /= max_val\n",
    "\n",
    "def one_hot_encode(Y):\n",
    "    encoded_Y = np.zeros((Y.size, Y.max()+1), dtype=int)\n",
    "    encoded_Y[np.arange(Y.size), Y] = 1 \n",
    "    return encoded_Y\n",
    "\n",
    "Y_train_encoded = one_hot_encode(Y_train)\n",
    "Y_eval_encoded = one_hot_encode(Y_eval)\n",
    "\n",
    "X_train.shape, Y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bede9247",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-02-05T17:09:35.144941Z",
     "iopub.status.busy": "2025-02-05T17:09:35.144557Z",
     "iopub.status.idle": "2025-02-05T17:09:35.170623Z",
     "shell.execute_reply": "2025-02-05T17:09:35.169499Z"
    },
    "papermill": {
     "duration": 0.032938,
     "end_time": "2025-02-05T17:09:35.172865",
     "exception": false,
     "start_time": "2025-02-05T17:09:35.139927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class MLP:\n",
    "    def __init__(self, hidden_layer_units = 128):\n",
    "        self.p = 28*28\n",
    "        self.h = hidden_layer_units\n",
    "        self.q = 10\n",
    "        \n",
    "        self.init_parameters()\n",
    "    \n",
    "    def init_parameters(self):\n",
    "        # [-0.5, 0.5) distribution\n",
    "        self.W1 = np.random.rand(self.h, self.p) - 0.5\n",
    "        self.b1 = np.random.rand(self.h) - 0.5\n",
    "        self.W2 = np.random.rand(self.q, self.h) - 0.5\n",
    "        self.b2 = np.random.rand(self.q) - 0.5\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_deriv(z):\n",
    "        return (z > 0).astype(float)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        z = np.clip(z, -500, 500) # Avoid possible errors\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_deriv(z):\n",
    "        s = MLP.sigmoid(z)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(pred, true):  # Categorical Cross-Entropy (CE)\n",
    "        return -np.sum(true * np.log(pred + 1e-8)) / true.shape[0]  # avoid log(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_deriv(pred, true):\n",
    "        return (pred - true) / true.shape[0]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.Z1 = self.W1.dot(x) + self.b1\n",
    "        self.A1 = MLP.relu(self.Z1)\n",
    "        self.Z2 = self.W2.dot(self.A1) + self.b2\n",
    "        self.A2 = MLP.sigmoid(self.Z2)\n",
    "    \n",
    "    def backward(self, x, y):\n",
    "        # deltas\n",
    "        dZ2 = MLP.loss_deriv(self.A2, y)\n",
    "        dZ1 = self.W2.T.dot(dZ2) * MLP.relu_deriv(self.Z1)\n",
    "\n",
    "        # gradients\n",
    "        dW2 = np.outer(dZ2, self.A1)\n",
    "        db2 = dZ2\n",
    "        dW1 = np.outer(dZ1, x)\n",
    "        db1 = dZ1\n",
    "        \n",
    "        return dW2, db2, dW1, db1      \n",
    "\n",
    "    def update_parameters(self, learning_rate, dW2_avg, db2_avg, dW1_avg, db1_avg):\n",
    "        self.W2 -= learning_rate * dW2_avg\n",
    "        self.b2 -= learning_rate * db2_avg\n",
    "        self.W1 -= learning_rate * dW1_avg\n",
    "        self.b1 -= learning_rate * db1_avg\n",
    "    \n",
    "    def train(self, X, Y, epochs = 10, learning_rate = 1e-2, batch_size = 128):\n",
    "        n = Y.shape[0]\n",
    "        batches = n // batch_size # Last incomplete batch won't be utilized\n",
    "        \n",
    "        # MGD\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for batch in range(batches):\n",
    "                grads_avg = list(map(np.zeros_like, (self.W2, self.b2, self.W1, self.b1)))\n",
    "                \n",
    "                for i in range(batch * batch_size, (batch+1) * batch_size):\n",
    "                    xi = X[i]\n",
    "                    yi = Y[i]\n",
    "\n",
    "                    self.forward(xi)\n",
    "                    loss = MLP.loss(self.A2, yi)\n",
    "                    epoch_loss += loss\n",
    "                    \n",
    "                    grads = self.backward(xi, yi)\n",
    "\n",
    "                    for grad, grad_avg in zip(grads, grads_avg):\n",
    "                        grad_avg += grad\n",
    "\n",
    "                for grad_avg in grads:\n",
    "                    grad_avg /= batch_size\n",
    "                    \n",
    "                self.update_parameters(learning_rate, *grads_avg)\n",
    "                \n",
    "            avg_epoch_loss = epoch_loss / (batches * batch_size)\n",
    "            print(f\"Epoch [{epoch + 1}] - Loss: {avg_epoch_loss}\")\n",
    "            \n",
    "    def evaluate(self, X, Y):\n",
    "        samples = X.shape[0]\n",
    "        correct = 0\n",
    "        for i in range(samples):\n",
    "            xi = X[i]\n",
    "            yi = Y[i]\n",
    "            self.forward(xi)\n",
    "            pred_class = np.argmax(self.A2)\n",
    "            true_class = np.argmax(yi)\n",
    "            if pred_class == true_class:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy = correct / X.shape[0]\n",
    "        print(f\"Samples: {samples} - Accuracy: {accuracy}\")     \n",
    "\n",
    "# Instatiate the model\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3be0718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:09:35.181952Z",
     "iopub.status.busy": "2025-02-05T17:09:35.181468Z",
     "iopub.status.idle": "2025-02-05T17:12:26.140738Z",
     "shell.execute_reply": "2025-02-05T17:12:26.139277Z"
    },
    "papermill": {
     "duration": 170.969461,
     "end_time": "2025-02-05T17:12:26.146297",
     "exception": false,
     "start_time": "2025-02-05T17:09:35.176836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Loss: 0.0763370920537275\n",
      "Epoch [2] - Loss: 0.03754357673716567\n",
      "Epoch [3] - Loss: 0.030551919587891125\n",
      "Epoch [4] - Loss: 0.026499887340552412\n",
      "Epoch [5] - Loss: 0.02369531969936041\n",
      "Epoch [6] - Loss: 0.02157728143142908\n",
      "Epoch [7] - Loss: 0.01988299113985059\n",
      "Epoch [8] - Loss: 0.01849147497019067\n",
      "Epoch [9] - Loss: 0.01730648360183963\n",
      "Epoch [10] - Loss: 0.016285131347502937\n",
      "Samples: 2000 - Accuracy: 0.961\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation\n",
    "mlp.train(X_train, Y_train_encoded)\n",
    "mlp.evaluate(X_eval, Y_eval_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5366b854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:12:26.157416Z",
     "iopub.status.busy": "2025-02-05T17:12:26.157061Z",
     "iopub.status.idle": "2025-02-05T17:12:26.487891Z",
     "shell.execute_reply": "2025-02-05T17:12:26.486503Z"
    },
    "papermill": {
     "duration": 0.338751,
     "end_time": "2025-02-05T17:12:26.490044",
     "exception": false,
     "start_time": "2025-02-05T17:12:26.151293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests\n",
    "sample = np.random.randint(1, test_data.shape[0])\n",
    "num = test_data[sample]\n",
    "\n",
    "plt.title(f\"Sample {sample}\")\n",
    "plt.imshow(num, cmap=\"gray\")\n",
    "mlp.forward(num.reshape(28*28))\n",
    "\n",
    "print(f\"Model prediction: {mlp.A2.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd8366",
   "metadata": {
    "papermill": {
     "duration": 0.004177,
     "end_time": "2025-02-05T17:12:26.499376",
     "exception": false,
     "start_time": "2025-02-05T17:12:26.495199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">Thanks for reading, \\\n",
    "> Uriel Rubio García | @[urubiog](https://www.github.com/urubiog)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 185.272621,
   "end_time": "2025-02-05T17:12:27.226932",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-05T17:09:21.954311",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
