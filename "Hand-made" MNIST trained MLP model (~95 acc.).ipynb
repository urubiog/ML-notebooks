{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b7a15d",
   "metadata": {
    "papermill": {
     "duration": 0.002844,
     "end_time": "2025-02-05T16:26:24.975215",
     "exception": false,
     "start_time": "2025-02-05T16:26:24.972371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "The MLP (Multi-Layer Perceptron) neural network model for handwritten digit prediction using the MNIST dataset in this example has a simple architecture, described below, along with its functionality.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "The first input layer depends on the resolution of the images, which in this case are 28x28 (784 pixels). The second layer contains a total of 128 units, and finally, the last layer has 10 neurons corresponding to the possible digits in the decimal base (0-9).\n",
    "\n",
    "$$\n",
    "\\text{784 - 128 - 10}\n",
    "$$\n",
    "\n",
    "### Activation Functions\n",
    "\n",
    "For the interests of simplicity, we choose the ReLU (Rectified Linear Unit) activation function for the hidden layer and Sigmoid for the final layer. This is because the Sigmoid function transforms the network's output (which can have any real values) into a value between 0 and 1, allowing each output to be interpreted as the probability of the corresponding class in a binary classification task. However, unlike Softmax, Sigmoid does not ensure that the sum of all outputs equals 1. Instead, each output is treated independently.\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(z) = \\max{(0, z)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Sigmoid}(Z) = \\frac{e^{z_i}}{\\sum_{j=1}^K{e^{z_j}}}\n",
    "$$\n",
    "\n",
    "And, the derivatives for each function...\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}z} \\text{ReLU}(z) = \n",
    "\\begin{cases} \n",
    "1 & \\text{if } z > 0 \\\\\n",
    "0 & \\text{if } z \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}Z} \\text{Sigmoid}(Z) = \\text{Sigmoid}(Z) \\cdot (1 - \\text{Sigmoid}(Z))\n",
    "$$\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "The Categorical Cross-Entropy (CE) function is used in classification problems, particularly when the output of the model is a probability distribution over multiple classes, as in the case of the softmax activation. In this case, the CE measures how well the predicted probability distribution matches the true class labels (0-9).\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} y_{ij} \\log (\\hat{y}_{ij})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_{ij}$ is the true label (1 if class $j$ is correct, 0 otherwise).\n",
    "- $\\hat{y}_{ij}$ is the predicted probability for class $j$ for example $i$.\n",
    "- $N$ is the number of training examples.\n",
    "- $K$ is the number of classes (for MNIST, $K = 10$).\n",
    "\n",
    "The derivative of the Categorical Cross-Entropy (CE) with respect to the predictions is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\hat{y}_{ij}} = \\frac{\\hat{y}_{ij} - y_{ij}}{N}\n",
    "$$\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "For the optimizer, we will use MGD (Mini-batch Gradient Descent) with a batch size $m$ of 128. Using the Backpropagation algorithm, we will reduce the loss by updating the parameters according to the differentiation of the previous functions, as shown in the adjacent formulas.\n",
    "\n",
    "The parameters (weights and biases) are updated as shown below. We introduce a new variable $\\delta$, which will be used to optimize the process and make it more manageable in terms of computational resources.\n",
    "\n",
    "$$\n",
    "\\delta^{L}_i = \\frac{\\partial{\\mathcal{L}}}{\\partial{z^L_i}} = \\frac{\\partial{\\mathcal{L}}}{\\partial{\\hat{y}^L_i}} · \\frac{\\partial{\\hat{y}^L_i}}{\\partial{z^L_i}}\n",
    "$$\n",
    "\n",
    "For the last layer $L$.\n",
    "\n",
    "$$\n",
    "\\delta^{(l-1)}_i = \\frac{\\partial{\\mathcal{L}}}{\\partial{z^{(l-1)}_i}} = \\left(\\sum_{j}{\\delta^{(l)}_j · w^{l}_{ij}}\\right) · \\frac{\\partial{a^{(l-1)}_i}}{\\partial{z^{(l-1)}_i}}\n",
    "$$\n",
    "\n",
    "For the layer preceding to $l$.\n",
    "\n",
    "$$\n",
    "b^{(l)}_i := b^{(l)}_i - \\alpha \\frac{\\partial{\\mathcal{L}}}{\\partial{b^{(l)}_{i}}} = \\delta^{(l)}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "w^{(l)}_{ij} := w^{(l)}_{ij} - \\alpha \\frac{\\partial{\\mathcal{L}}}{\\partial{w^{(l)}_{ij}}} = \\delta^{(l)}_i · a^{(l-1)}_j\n",
    "$$\n",
    "\n",
    "For each iteration.\n",
    "\n",
    "$$\n",
    "\\theta := \\theta - \\eta \\frac{1}{m} \\sum^{m}_{i=1}{\\nabla_{\\theta} \\mathcal{L}(\\theta;x^{(i)}, y^{(i)})}\n",
    "$$\n",
    "\n",
    "For each batch.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Regarding hyperparameters, we will use standardized values:\n",
    "\n",
    "$$\n",
    "\\eta: \\text{learning rate} = 0.01\n",
    "$$\n",
    "\n",
    "$$\n",
    "m: \\text{batch size} = 128\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d441a61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:26:24.986382Z",
     "iopub.status.busy": "2025-02-05T16:26:24.986048Z",
     "iopub.status.idle": "2025-02-05T16:26:25.940211Z",
     "shell.execute_reply": "2025-02-05T16:26:25.939427Z"
    },
    "papermill": {
     "duration": 0.959563,
     "end_time": "2025-02-05T16:26:25.941869",
     "exception": false,
     "start_time": "2025-02-05T16:26:24.982306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b09683f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:26:25.947867Z",
     "iopub.status.busy": "2025-02-05T16:26:25.947416Z",
     "iopub.status.idle": "2025-02-05T16:26:30.521277Z",
     "shell.execute_reply": "2025-02-05T16:26:30.520199Z"
    },
    "papermill": {
     "duration": 4.578195,
     "end_time": "2025-02-05T16:26:30.522586",
     "exception": false,
     "start_time": "2025-02-05T16:26:25.944391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "train_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ead2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:26:30.530771Z",
     "iopub.status.busy": "2025-02-05T16:26:30.530419Z",
     "iopub.status.idle": "2025-02-05T16:26:30.606071Z",
     "shell.execute_reply": "2025-02-05T16:26:30.605201Z"
    },
    "papermill": {
     "duration": 0.080783,
     "end_time": "2025-02-05T16:26:30.607391",
     "exception": false,
     "start_time": "2025-02-05T16:26:30.526608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 40000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data division\n",
    "data = np.array(train_data) # 42_000 examples\n",
    "test_data = np.array(test_data)   # 28_000 examples (without labels)\n",
    "\n",
    "m, n = train_data.shape\n",
    "\n",
    "train_data = data[2000:m].T\n",
    "X_train = train_data[1: n]\n",
    "Y_train = train_data[0]\n",
    "\n",
    "eval_data = data[:2000].T\n",
    "X_eval = eval_data[1: n]\n",
    "Y_eval = eval_data[0]\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722716b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:26:30.613372Z",
     "iopub.status.busy": "2025-02-05T16:26:30.613074Z",
     "iopub.status.idle": "2025-02-05T16:26:30.708022Z",
     "shell.execute_reply": "2025-02-05T16:26:30.707287Z"
    },
    "papermill": {
     "duration": 0.099626,
     "end_time": "2025-02-05T16:26:30.709641",
     "exception": false,
     "start_time": "2025-02-05T16:26:30.610015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 784), (40000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "test_data = test_data.reshape(28000, 28, 28)\n",
    "\n",
    "X_train = X_train.astype(np.float64).T\n",
    "X_train /= 255.0 # Normalization\n",
    "X_eval = X_eval.astype(np.float64).T\n",
    "\n",
    "X_eval /= 255.0\n",
    "\n",
    "def one_hot_encode(Y):\n",
    "    encoded_Y = np.zeros((Y.size, Y.max()+1), dtype=int)\n",
    "    encoded_Y[np.arange(Y.size), Y] = 1 \n",
    "    return encoded_Y\n",
    "\n",
    "Y_train_encoded = one_hot_encode(Y_train)\n",
    "Y_eval_encoded = one_hot_encode(Y_eval)\n",
    "\n",
    "X_train.shape, Y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c805bd",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-02-05T16:26:30.715935Z",
     "iopub.status.busy": "2025-02-05T16:26:30.715637Z",
     "iopub.status.idle": "2025-02-05T16:26:30.738217Z",
     "shell.execute_reply": "2025-02-05T16:26:30.737439Z"
    },
    "papermill": {
     "duration": 0.027322,
     "end_time": "2025-02-05T16:26:30.739822",
     "exception": false,
     "start_time": "2025-02-05T16:26:30.712500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class MLP:\n",
    "    def __init__(self, hidden_layer_units = 128):\n",
    "        self.p = 28*28\n",
    "        self.h = hidden_layer_units\n",
    "        self.q = 10\n",
    "        \n",
    "        self.init_parameters()\n",
    "    \n",
    "    def init_parameters(self):\n",
    "        self.W1 = np.random.rand(self.h, self.p) - 0.5\n",
    "        self.b1 = np.random.rand(self.h) - 0.5\n",
    "        self.W2 = np.random.rand(self.q, self.h) - 0.5\n",
    "        self.b2 = np.random.rand(self.q) - 0.5\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_deriv(z):\n",
    "        return (z > 0).astype(float)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        z = np.clip(z, -500, 500) # Avoid possible errors\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_deriv(z):\n",
    "        s = MLP.sigmoid(z)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(pred, true):  # Categorical Cross-Entropy (CE)\n",
    "        return -np.sum(true * np.log(pred + 1e-8)) / true.shape[0]  # avoid log(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_deriv(pred, true):\n",
    "        return (pred - true) / true.shape[0]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.Z1 = self.W1.dot(x) + self.b1\n",
    "        self.A1 = MLP.relu(self.Z1)\n",
    "        self.Z2 = self.W2.dot(self.A1) + self.b2\n",
    "        self.A2 = MLP.sigmoid(self.Z2)\n",
    "    \n",
    "    def backward(self, x, y):\n",
    "        # deltas\n",
    "        dZ2 = MLP.loss_deriv(self.A2, y)\n",
    "        dZ1 = self.W2.T.dot(dZ2) * MLP.relu_deriv(self.Z1)\n",
    "\n",
    "        # gradients\n",
    "        dW2 = np.outer(dZ2, self.A1)\n",
    "        db2 = dZ2\n",
    "        dW1 = np.outer(dZ1, x)\n",
    "        db1 = dZ1\n",
    "        \n",
    "        return dW2, db2, dW1, db1      \n",
    "\n",
    "    def update_parameters(self, learning_rate, dW2, db2, dW1, db1):\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def train(self, X, Y, epochs = 10, learning_rate = 1e-2, batch_size = 128):\n",
    "        n = Y.shape[0]\n",
    "        batches = n // batch_size\n",
    "        \n",
    "        # MGD\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = -1\n",
    "            \n",
    "            for batch in range(batches):\n",
    "                grads_avg = list(map(np.zeros_like, (self.W2, self.b2, self.W1, self.b1)))\n",
    "                \n",
    "                for i in range(batch * batch_size, (batch+1) * batch_size):\n",
    "                    xi = X[i]\n",
    "                    yi = Y[i]\n",
    "\n",
    "                    self.forward(xi)\n",
    "                    loss = MLP.loss(self.A2, yi)\n",
    "                    epoch_loss += loss\n",
    "                    \n",
    "                    grads = self.backward(xi, yi)\n",
    "\n",
    "                    for grad, grad_avg in zip(grads, grads_avg):\n",
    "                        grad_avg += grad\n",
    "\n",
    "                for grad_avg in grads:\n",
    "                    grad_avg /= batch_size\n",
    "                    \n",
    "                self.update_parameters(learning_rate, *grads_avg)\n",
    "                \n",
    "            avg_epoch_loss = epoch_loss / (batches * batch_size)\n",
    "            print(f\"Epoch [{epoch + 1}] - Loss: {avg_epoch_loss}\")\n",
    "            \n",
    "    def evaluate(self, X, Y):\n",
    "        samples = X.shape[0]\n",
    "        correct = 0\n",
    "        for i in range(samples):\n",
    "            xi = X[i]\n",
    "            yi = Y[i]\n",
    "            self.forward(xi)\n",
    "            pred_class = np.argmax(self.A2)\n",
    "            true_class = np.argmax(yi)\n",
    "            if pred_class == true_class:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy = correct / X.shape[0]\n",
    "        print(f\"Samples: {samples} - Accuracy: {accuracy}\")     \n",
    "\n",
    "# Instatiate the model\n",
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c683bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:26:30.746443Z",
     "iopub.status.busy": "2025-02-05T16:26:30.746156Z",
     "iopub.status.idle": "2025-02-05T16:28:05.454113Z",
     "shell.execute_reply": "2025-02-05T16:28:05.453294Z"
    },
    "papermill": {
     "duration": 94.712266,
     "end_time": "2025-02-05T16:28:05.455245",
     "exception": false,
     "start_time": "2025-02-05T16:26:30.742979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Loss: 0.07926330025740073\n",
      "Epoch [2] - Loss: 0.03877011731165504\n",
      "Epoch [3] - Loss: 0.03147948751164459\n",
      "Epoch [4] - Loss: 0.0272024067549298\n",
      "Epoch [5] - Loss: 0.0242655497352445\n",
      "Epoch [6] - Loss: 0.022036703374559857\n",
      "Epoch [7] - Loss: 0.02024862616776484\n",
      "Epoch [8] - Loss: 0.018764893726841224\n",
      "Epoch [9] - Loss: 0.017487276475714533\n",
      "Epoch [10] - Loss: 0.01638100307977788\n",
      "Samples: 2000 - Accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation\n",
    "mlp.train(X_train, Y_train_encoded)\n",
    "mlp.evaluate(X_eval, Y_eval_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6683831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T16:28:05.461996Z",
     "iopub.status.busy": "2025-02-05T16:28:05.461700Z",
     "iopub.status.idle": "2025-02-05T16:28:05.698663Z",
     "shell.execute_reply": "2025-02-05T16:28:05.697914Z"
    },
    "papermill": {
     "duration": 0.242194,
     "end_time": "2025-02-05T16:28:05.700511",
     "exception": false,
     "start_time": "2025-02-05T16:28:05.458317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tests\n",
    "sample = np.random.randint(1, test_data.shape[0])\n",
    "num = test_data[sample]\n",
    "\n",
    "plt.title(f\"Sample {sample}\")\n",
    "plt.imshow(num, cmap=\"gray\")\n",
    "mlp.forward(num.reshape(28*28))\n",
    "\n",
    "print(f\"Model prediction: {mlp.A2.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16103d",
   "metadata": {
    "papermill": {
     "duration": 0.003087,
     "end_time": "2025-02-05T16:28:05.707517",
     "exception": false,
     "start_time": "2025-02-05T16:28:05.704430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">Thanks for reading, \\\n",
    "> Uriel Rubio García | @[urubiog](https://www.github.com/urubiog)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 103.684533,
   "end_time": "2025-02-05T16:28:06.331181",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-05T16:26:22.646648",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
